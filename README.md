# ðŸ˜„ Facial Emotion Recognition with CNN & MediaPipe

This project implements a **real-time facial emotion recognition system** using a **Convolutional Neural Network (CNN)** trained on the **FER-2013** dataset and face mesh detection using **MediaPipe**. It captures webcam input, detects facial landmarks, and predicts emotional states like Happy, Sad, Angry, etc., on-the-fly.

---

## ðŸ§  What It Does

âœ… Detects faces using MediaPipe  
âœ… Applies 468-point face mesh with light styling  
âœ… Predicts emotions like ðŸ˜  ðŸ˜¢ ðŸ˜ ðŸ˜® ðŸ˜ from facial expressions  
âœ… Uses a CNN trained on **FER-2013 dataset**  
âœ… Runs live via webcam (OpenCV) â€” No images saved!


---

## ðŸ“¦ Dataset Used

- **FER-2013 (Facial Expression Recognition 2013)**
- Download from: https://www.kaggle.com/datasets/msambare/fer2013
- Format: Pre-separated folder structure with `train/` and `validation/` directories.
- Each should contain 7 folders: angry/, disgust/, fear/, happy/, neutral/, sad/, surprise/

### workflow
> - pip install -r requirements.txt
> - facial_emo_recognition/
> - â””â”€â”€ dataset/
>    - â”œâ”€â”€ train/
>    - â””â”€â”€ validation/
> - python train_emo_model.py
>  run
> - python main.py



